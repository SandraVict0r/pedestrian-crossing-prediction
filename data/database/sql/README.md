Parfait â€” ton README est **dÃ©jÃ  propre, clair et bien structurÃ©**.
Je te propose **quelques amÃ©liorations ciblÃ©es**, pour :

* corriger 2â€“3 imprÃ©cisions,
* clarifier le pipeline,
* harmoniser la nomenclature,
* ajouter les liens cliquables cohÃ©rents avec lâ€™arborescence que tu as maintenant,
* et renforcer la cohÃ©rence entre SQL â†” Python â†” processed data.

Voici la **version optimisÃ©e** (tu peux remplacer ton README directement avec) :

---

# ğŸ“ `data/database/sql/` â€” README

## ğŸ“Œ Objectif du dossier

Ce dossier contient **tous les scripts SQL utilisÃ©s pour construire la base de donnÃ©es MySQL du projet**, nettoyer certaines donnÃ©es et gÃ©nÃ©rer le tableau final utilisÃ© pour l'entraÃ®nement des modÃ¨les de prÃ©diction du comportement de traversÃ©e.

Ces scripts sont exÃ©cutÃ©s :

1. **aprÃ¨s la collecte des donnÃ©es brutes** (`data/raw/`)
2. **aprÃ¨s lâ€™insertion dans MySQL** via les scripts Python
3. **avant la gÃ©nÃ©ration des CSV propres** stockÃ©s dans `data/processed/`

---

## ğŸ“‚ Contenu du dossier

```
sql/
 â”£ bdd_creator.sql
 â”£ bad_datas_to_remove.sql
 â”— model_datas_request.sql
```

---

# 1. `bdd_creator.sql` â€” CrÃ©ation de la base

Script **principal** pour initialiser la base de donnÃ©es :

* crÃ©e la base `main_experiment`

* crÃ©e les tables :

  * `Participant`
  * `Weather`
  * `Position`
  * `Velocity`
  * `DistanceDisappearance`
  * `Perception`
  * `Crossing`

* insÃ¨re les paramÃ¨tres fixes :

  * conditions mÃ©tÃ©o (`clear`, `night`, `rain`)
  * positions (0, 1, 2)
  * vitesses + catÃ©gories (`low`, `medium`, `high`)
  * distances + catÃ©gories (`pair`, `odd`)

ğŸ‘‰ **Ce script doit Ãªtre exÃ©cutÃ© en premier lors dâ€™une reconstruction complÃ¨te.**

---

# 2. `bad_datas_to_remove.sql` â€” Suppression des outliers

Ce script retire **les participants/essais identifiÃ©s comme outliers**
(ex. enregistrements corrompus, comportement hors protocole, donnÃ©es incomplÃ¨tes).

Il supprime :

* les entrÃ©es correspondantes dans `Perception`
* les entrÃ©es correspondantes dans `Crossing`
* le participant dans `Participant`

âš ï¸ **Important : ce script est indispensable pour garantir que seuls les essais valides sont conservÃ©s.**

---

# 3. `model_datas_request.sql` â€” Construction du dataset ML

Script qui produit une **vue tabulaire complÃ¨te**, incluant :

* informations participant
* distances perÃ§ues (regroupÃ©es : `D_low`, `D_med`, `D_high`)
* distances rÃ©elles
* vitesses (exp1 & exp2)
* catÃ©gories de conditions expÃ©rimentales
* variables dÃ©rivÃ©es
* **moyennes des Safety Distances** (par vitesse / mÃ©tÃ©o / participant)

ğŸ¯ Ce script gÃ©nÃ¨re **le tableau final utilisÃ© pour entraÃ®ner les modÃ¨les ML**.

---

## ğŸ“¤ Export CSV

Une fois la requÃªte exÃ©cutÃ©e, la table finale doit Ãªtre exportÃ©e en CSV dans :

ğŸ‘‰ [`data/processed/`](../../processed/)

Câ€™est ici que se trouvent **tous les jeux de donnÃ©es propres et prÃªts pour lâ€™entraÃ®nement**.

---

# ğŸ”— DÃ©pendances

Ces scripts SQL fonctionnent conjointement avec les scripts Python du dossier :

```
data/database/python/
```

Les scripts Python :

* lisent les donnÃ©es brutes dans `data/raw/`
* extraient les distances perÃ§ues (exp1)
* gÃ©nÃ¨rent les sÃ©quences de crossing (exp2)
* insÃ¨rent toutes les valeurs expÃ©rimentales dans MySQL via `db_utils.py`

âš™ï¸ Ils doivent Ãªtre exÃ©cutÃ©s **juste aprÃ¨s `bdd_creator.sql`**.

---

# ğŸ“Œ Pipeline dâ€™utilisation (ordre recommandÃ©)

1. **CrÃ©er la base**

   ```
   bdd_creator.sql
   ```

2. **InsÃ©rer les donnÃ©es**

   ```
   python insert_participant_data_to_mysql.py
   python insert_perception_experiment_data_to_mysql.py
   python insert_crossing_experiment_data_to_mysql.py
   ```

3. **Supprimer les outliers**

   ```
   bad_datas_to_remove.sql
   ```

4. **GÃ©nÃ©rer la table finale**

   ```
   model_datas_request.sql
   ```

5. **Exporter le rÃ©sultat**

   * via MySQL Workbench
   * ou via un script Python utilisant pandas
     dans :
     ğŸ‘‰ `data/processed/model_training/`

